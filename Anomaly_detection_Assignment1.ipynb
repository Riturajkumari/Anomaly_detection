{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqGcfQqHWaBz/4FJ5lWqXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riturajkumari/Anomaly_detection/blob/main/Anomaly_detection_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is anomaly detection and what is its purpose?**"
      ],
      "metadata": {
        "id": "habGouXXliZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Anomaly detection is the process of identifying rare events, items, or observations that deviate from normal behavior or patterns in data. It is a process in machine learning that is critical for industrial applications like predictive and prescriptive maintenance.\n",
        "-  Anomaly Detector is a core engine of Metrics Advisor that detects anomalies in time-series data using simple REST APIs.\n",
        "-  Companies use anomalous activity detection to define system baselines, identify deviations from that baseline, and investigate inconsistent data."
      ],
      "metadata": {
        "id": "I7rvMIyrm1sv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yXSPEwTln7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. What are the key challenges in anomaly detection?**"
      ],
      "metadata": {
        "id": "G1M1aM2kltDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenges in anomaly detection can include:\n",
        "\n",
        "- Extracting useful features appropriately\n",
        "- Defining what is considered “normal”\n",
        "- Dealing with the situations where there are significantly more normal values than anomalies\n",
        "- Separating noise from real outliers\n",
        "- Difficulties brought by anomaly detection can be brought on by both high dimensionality and the enormous amount of data."
      ],
      "metadata": {
        "id": "gDhYG1rfpDrg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUsZXncRlyLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?**"
      ],
      "metadata": {
        "id": "qL1xDfk0lyXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Unsupervised anomaly detection is the process of identifying unexpected items or events in unlabeled datasets, which differ from the norm. It does not require any prior knowledge about the anomalies, but assumes that they are rare and make up a small percentage of the data.\n",
        "- It involves modelling the normal data distribution and defining a measurement to classify samples as anomalous or normal. It is often applied in practical applications such as network intrusion detection, fraud detection, and life science and medical domain."
      ],
      "metadata": {
        "id": "uThRprQ_pj5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Supervised anomaly detection requires labeled data that indicates if a record is normal or abnormal. Any modeling technique for binary responses will work here, e.g. logistic regression or gradient boosting. The typical application is fraud detection."
      ],
      "metadata": {
        "id": "CmOMxFrlp4LI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xZ0m0Bdl2LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. What are the main categories of anomaly detection algorithms?**\n",
        "\n"
      ],
      "metadata": {
        "id": "voTCNtZal3Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following algorithms are commonly used for anomaly detection**\n",
        "- Auto-Encoders\n",
        "- Gaussian Mixture Models\n",
        "- Kernel Density Estimation\n",
        "- Self-organizing maps (SOM)\n",
        "- K-means\n",
        "- C-means\n",
        "- Expectation-maximization meta-algorithm (EM)\n",
        "- Adaptive resonance theory (ART)"
      ],
      "metadata": {
        "id": "75PdmoNCqOyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Isolation Forest:\n",
        "\n",
        "Isolation Forest is an unsupervised anomaly detection algorithm that uses a random forest algorithm (decision trees) under the hood to detect outliers in the dataset. The algorithm tries to split or divide the data points such that each observation gets isolated from the others."
      ],
      "metadata": {
        "id": "DtKDy0zzsN5A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geWfiOnsl-pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. What are the main assumptions made by distance-based anomaly detection methods?**"
      ],
      "metadata": {
        "id": "U_MYT7d5l-1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distance-based anomaly detection approaches rely on distance calculations between points and sets of points. The main assumptions made by distance-based anomaly detection methods are:\n",
        "\n",
        "\n",
        "- Normal data points occur around a dense neighborhood and abnormalities are far away .\n",
        "- Anomalies are defined as data points that are far from their nearest neighbors .\n",
        "- Anomalies are defined as data points that have a small number of close neighbors"
      ],
      "metadata": {
        "id": "1n2HbztisfxT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOIaAyZcmGpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. How does the LOF algorithm compute anomaly scores?**"
      ],
      "metadata": {
        "id": "v_ZA1xkHmG0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors.\n",
        "- The LOF algorithm computes an anomaly score for each sample in the dataset. The score is based on the local density of its neighbors. The higher the score, the more likely it is that the sample is an outlier."
      ],
      "metadata": {
        "id": "VAdxT79Zs7Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bK5QBVLomNDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What are the key parameters of the Isolation Forest algorithm?"
      ],
      "metadata": {
        "id": "FnPlVXukmNfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Isolation Forest algorithm is an unsupervised learning algorithm used for anomaly detection. The important parameters in the algorithm are:**\n",
        "\n",
        "- Number of trees / estimators: how big is the forest.\n",
        "- Contamination: the fraction of the dataset that contains abnormal instances.\n",
        "- Max samples: The number of samples to draw from the training set to train each Isolation Tree with.\n",
        "- Max depth: how deep the tree should be, this can be used to trim the tree and make things faster."
      ],
      "metadata": {
        "id": "xhOaXPBetojJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnLfxLewmRl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
        "using KNN with K=10?"
      ],
      "metadata": {
        "id": "t-W8YKUAmTcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The anomaly score of a data point is the inverse of the average distance between the point and its k nearest neighbors. In this case, k=10. If a data point has only 2 neighbors of the same class within a radius of 0.5, then it has only 2 neighbors within that radius. Therefore, its anomaly score will be infinite."
      ],
      "metadata": {
        "id": "ozDUTzdkuL-V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uik3FIssmad5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
        "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
        "length of the trees?"
      ],
      "metadata": {
        "id": "mGohRL1jmaqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points can be calculated using the formula:\n",
        "\n",
        "  score = 2- E(h(x))/c(n)\n",
        "  where E(h(x)) is the average path length of the data point across all trees, n is the number of data points in the dataset, and c(n) is a normalization factor that can be approximated by:\n",
        "  c(n)= 2H(n-1)-2(n-1)/n\n",
        "  where H(i) is the harmonic number\n",
        "  "
      ],
      "metadata": {
        "id": "4UvmdpOqut2k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QhVCtzG4mc3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}