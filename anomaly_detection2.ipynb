{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1VQm1nVFDaGNpV9oaMq3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riturajkumari/Anomaly_detection/blob/main/anomaly_detection2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is the role of feature selection in anomaly detection?**"
      ],
      "metadata": {
        "id": "rpfPC3VVykTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feature selection is an important factor in modeling anomaly-based intrusion detection systems. Since anomaly detection systems often need to handle large amounts of data, feature selection is usually applied to reduce data complexity and optimize classification accuracy and running time.\n",
        "-  An irrelevant feature can result in overfitting and affect the modeling power of classification algorithms.\n",
        "- Therefore, feature selection is applied as a pre-processing step for anomaly detection systems in order to optimize their classification accuracy and running time."
      ],
      "metadata": {
        "id": "VqQYBN2dzxU0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HKkoV47EylyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. What are some common evaluation metrics for anomaly detection algorithms and how are they\n",
        "computed?**"
      ],
      "metadata": {
        "id": "Z2o5WBJZypbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Performance metrics for anomaly detection models are mainly based on Boolean anomaly/expected labels assigned to a given data point such as Precision, Recall, F-score, Accuracy and AUC .\n",
        "- These metrics are computed using the confusion matrix which is a table that is used to evaluate the performance of a classification algorithm .\n",
        "- The confusion matrix consists of four values: true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) ."
      ],
      "metadata": {
        "id": "oYUOQJVi1J_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Precision is the ratio of true positives to the sum of true positives and false positives. It measures how many of the predicted anomalies are actually anomalous .\n",
        "- Recall is the ratio of true positives to the sum of true positives and false negatives. It measures how many of the actual anomalies were detected by the algorithm .\n",
        "- F-score is the harmonic mean of precision and recall . Accuracy is the ratio of correctly classified data points to all data points . AUC (Area Under Curve) is a measure of how well a binary classification model can distinguish between two classes ."
      ],
      "metadata": {
        "id": "yLRM-C3s1SD8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s42X_WaVyqp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. What is DBSCAN and how does it work for clustering?**"
      ],
      "metadata": {
        "id": "3WHcWn_fyrN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DBSCAN stands for Density-Based Spatial Clustering of Applications with Noise. It is a density-based clustering algorithm that groups together points that are close to each other based on a distance measurement and a minimum number of points.\n",
        "-  The algorithm works by defining clusters as continuous regions of high density and works well if all the clusters are dense enough and well separated by low-density regions.\n",
        "- The algorithm has two main parameters: epsilon and minPoints.\n",
        "   -  Epsilon is the radius of the neighborhood around each point, and  \n",
        "   - minPoints is the minimum number of points required to form a dense region.\n",
        "- The algorithm starts by selecting an arbitrary point and finding all the points within epsilon distance from it. If there are more than minPoints points within this radius, then a new cluster is formed. If not, the point is labeled as noise."
      ],
      "metadata": {
        "id": "qMwwMIv811oz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4lznGjkyvJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. How does the epsilon parameter affect the performance of DBSCAN in detecting anomalies?**"
      ],
      "metadata": {
        "id": "n8UGRzhxyvXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The epsilon parameter in DBSCAN is used to define the radius of the neighborhood around a data point. The minPts parameter is used to define the minimum number of points required to form a dense region.\n",
        "-  The performance of DBSCAN in detecting anomalies is affected by the value of epsilon. If epsilon is too small, then the algorithm may not be able to detect large clusters. If epsilon is too large, then the algorithm may detect too many clusters and may not be able to detect small clusters ."
      ],
      "metadata": {
        "id": "MCORwfar20_m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YK9djkOky0Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. What are the differences between the core, border, and noise points in DBSCAN, and how do they relate\n",
        "to anomaly detection?**"
      ],
      "metadata": {
        "id": "zeyuu98ry0jA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm that groups together points that are close to each other based on a distance measurement (usually Euclidean distance) and a minimum number of points. The algorithm identifies three types of points: core points, border points, and noise points.**\n",
        "\n",
        "- Core points are data points that have at least MinPts (a user-defined parameter) data points within a radius of Eps (another user-defined parameter).\n",
        "- Border points are data points that have fewer than MinPts data points within Eps but are in the neighborhood of a core point.\n",
        "- Noise points are data points that are neither core nor border points 12."
      ],
      "metadata": {
        "id": "_gGA2GjP3L_l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iloxIfYny4sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. How does DBSCAN detect anomalies and what are the key parameters involved in the process?**"
      ],
      "metadata": {
        "id": "hwdbkUsIy-Qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DBSCAN is a density-based clustering algorithm that works on the assumption that clusters are dense regions in space separated by regions of lower density. It groups ‘densely grouped’ data points into a single cluster. It can identify clusters in large spatial datasets by looking at the local density of the data points. The algorithm takes multi-dimensional data as inputs and clusters them according to the model parameters — e.g. epsilon and minimum samples. Based on these parameters, the algorithm determines whether certain values in the dataset are outliers or not.\n",
        "\n"
      ],
      "metadata": {
        "id": "-_yRcwN-37-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key parameters involved in the process are:\n",
        "\n",
        "- Epsilon: It is a measure of the neighborhood. It is a number that represents the radius of the circle around a particular point that we are going to consider the neighborhood of that point.\n",
        "- Minimum Samples: It is a threshold on the least number of points that we want to see in a point’s neighborhood"
      ],
      "metadata": {
        "id": "3sayLr-l4RAD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VpLOS8tNzAd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. What is the make_circles package in scikit-learn used for?**"
      ],
      "metadata": {
        "id": "Rt0lNhRozAp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The make_circles function in scikit-learn is used to generate a large circle containing a smaller circle in 2D. It is a simple toy dataset that can be used to visualize clustering and classification algorithms.\n",
        "- The function generates samples with two classes, where one class is the inner circle and the other is the outer circle. The number of samples can be specified using the n_samples parameter."
      ],
      "metadata": {
        "id": "dNdQNGQq4iAC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFjpl_EnzFCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What are local outliers and global outliers, and how do they differ from each other?**"
      ],
      "metadata": {
        "id": "SU9teOUuzFPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Outliers are data points that deviate significantly from the rest of the data points. They can be classified into two types: global and local.\n",
        "- Global outliers fall outside the normal range for an entire dataset. For example, if 99 out of 100 points have values between 300 and 400, but the 100th point has a value of 750, the 100th point may be a global outlier.\n",
        "- Local outliers may fall within the normal range for the entire dataset but outside the normal range for the surrounding data points. For example, a measured sample point that has a value within the normal range for the entire dataset but if you look at the surrounding points, it is unusually high or low.\n",
        "- In summary, global outliers are data points that deviate significantly from the overall distribution of a dataset while local outliers are data points that deviate significantly from their surrounding data points."
      ],
      "metadata": {
        "id": "71GmLcOs44ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pt6zLmUgzK1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. How can local outliers be detected using the Local Outlier Factor (LOF) algorithm?**"
      ],
      "metadata": {
        "id": "LuqWbMxvzNjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors.\n",
        "- It considers as outliers the samples that have a substantially lower density than their neighbors. The algorithm produces an anomaly score that represents data points which are outliers in the data set"
      ],
      "metadata": {
        "id": "PJ38WurZ6nI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The LOF algorithm can be used to detect local outliers by computing the LOF of each data point. The LOF of a data point measures the degree of its outlier-ness relative to its neighbors. A data point is considered an outlier if its LOF score is significantly higher than those of its neighbors."
      ],
      "metadata": {
        "id": "Ulwer3Lp6qul"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqrHzHzgzPd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. How can global outliers be detected using the Isolation Forest algorithm?**"
      ],
      "metadata": {
        "id": "zkPRjIgrzPpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Isolation Forest algorithm is an algorithm that detects outliers by randomly selecting features and splitting the dataset into different branches. The algorithm partitions the data using a set of trees and provides an anomaly score looking at how isolated the point is in the structure found. The outliers have a high chance to be isolated faster than the normal points.\n",
        "-  The approach employs binary trees to detect anomalies, resulting in a linear time complexity and low memory usage that is well-suited for processing large datasets.\n",
        "- To detect global outliers using the Isolation Forest algorithm, you can use the following steps:\n",
        "\n",
        "   - Train an Isolation Forest model on your dataset.\n",
        "   - Predict the anomaly scores for each data point in your dataset.\n",
        "   - Sort the anomaly scores in descending order.\n",
        "   - Select the top n data points with the highest anomaly scores as global\n",
        "  outliers."
      ],
      "metadata": {
        "id": "3jpPls1h6_AC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsiK7NPyzX3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11. What are some real-world applications where local outlier detection is more appropriate than global\n",
        "outlier detection, and vice versa?**"
      ],
      "metadata": {
        "id": "zk75g5v5zYL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOD has proven to be an effective tool for identifying irregularities in many types of data-driven applications, such as fraud detection, customer segmentation, biometric systems and anomaly detection in sensor networks."
      ],
      "metadata": {
        "id": "8anj4uIZ7sO3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNUfkkP0zc_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}